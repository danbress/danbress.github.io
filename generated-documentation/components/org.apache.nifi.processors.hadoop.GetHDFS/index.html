<!DOCTYPE html><html lang="en"><!--Licensed to the Apache Software Foundation (ASF) under one or more
      contributor license agreements.  See the NOTICE file distributed with
      this work for additional information regarding copyright ownership.
      The ASF licenses this file to You under the Apache License, Version 2.0
      (the "License"); you may not use this file except in compliance with
      the License.  You may obtain a copy of the License at
          http://www.apache.org/licenses/LICENSE-2.0
      Unless required by applicable law or agreed to in writing, software
      distributed under the License is distributed on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
      See the License for the specific language governing permissions and
      limitations under the License.--><head><meta charset="utf-u"></meta><title>GetHDFS</title><link rel="stylesheet" href="../../css/component-usage.css" type="text/css"></link></head><body><h2>Description: </h2><p>Fetch files from Hadoop Distributed File System (HDFS) into FlowFiles</p><p><a href="additionalDetails.html">Additional Details...</a></p><p>Tags: hadoop, HDFS, get, fetch, ingest, source, filesystem</p><p><strong>Properties: </strong></p><p>In the list below, the names of required properties appear in bold. Any other properties (not in bold) are considered optional. If a property has a default value, it is indicated. If a property supports the use of the NiFi Expression Language (or simply, "expression language"), that is also indicated.</p><table><tr><th>Name</th><th>Description</th><th>Default Value</th><th>Valid Values</th><th><a href="../../html/expression-language-guide.html">EL</a></th><th>Sensitive</th></tr><tr><td>Hadoop Configuration Resources</td><td>A file or comma separated list of files which contains the Hadoop file system configuration. Without this, Hadoop will search the classpath for a 'core-site.xml' and 'hdfs-site.xml' file or will revert to a default configuration.</td><td></td><td></td><td>No</td><td>No</td></tr><tr><td><strong>Directory</strong></td><td>The HDFS directory from which files should be read</td><td></td><td></td><td>No</td><td>No</td></tr><tr><td><strong>Recurse Subdirectories</strong></td><td>Indicates whether to pull files from subdirectories of the HDFS directory</td><td>true</td><td><ul><li>true</li><li>false</li></ul></td><td>No</td><td>No</td></tr><tr><td><strong>Keep Source File</strong></td><td>Determines whether to delete the file from HDFS after it has been successfully transferred</td><td>false</td><td><ul><li>true</li><li>false</li></ul></td><td>No</td><td>No</td></tr><tr><td>File Filter Regex</td><td>A Java Regular Expression for filtering Filenames; if a filter is supplied then only files whose names match that Regular Expression will be fetched, otherwise all files will be fetched</td><td></td><td></td><td>No</td><td>No</td></tr><tr><td><strong>Filter Match Name Only</strong></td><td>If true then File Filter Regex will match on just the filename, otherwise subdirectory names will be included with filename in the regex comparison</td><td>true</td><td><ul><li>true</li><li>false</li></ul></td><td>No</td><td>No</td></tr><tr><td><strong>Ignore Dotted Files</strong></td><td>If true, files whose names begin with a dot (".") will be ignored</td><td>true</td><td><ul><li>true</li><li>false</li></ul></td><td>No</td><td>No</td></tr><tr><td><strong>Minimum File Age</strong></td><td>The minimum age that a file must be in order to be pulled; any file younger than this amount of time (based on last modification date) will be ignored</td><td>0 sec</td><td></td><td>No</td><td>No</td></tr><tr><td>Maximum File Age</td><td>The maximum age that a file must be in order to be pulled; any file older than this amount of time (based on last modification date) will be ignored</td><td></td><td></td><td>No</td><td>No</td></tr><tr><td><strong>Polling Interval</strong></td><td>Indicates how long to wait between performing directory listings</td><td>0 sec</td><td></td><td>No</td><td>No</td></tr><tr><td><strong>Batch Size</strong></td><td>The maximum number of files to pull in each iteration, based on run schedule.</td><td>100</td><td></td><td>No</td><td>No</td></tr><tr><td>IO Buffer Size</td><td>Amount of memory to use to buffer file contents during IO. This overrides the Hadoop Configuration</td><td></td><td></td><td>No</td><td>No</td></tr></table><p><strong>Relationships: </strong></p><table><tr><th>Name</th><th>Description</th></tr><tr><td>passthrough</td><td>If this processor has an input queue for some reason, then FlowFiles arriving on that input are transferred to this relationship</td></tr><tr><td>success</td><td>All files retrieved from HDFS are transferred to this relationship</td></tr></table></body></html>